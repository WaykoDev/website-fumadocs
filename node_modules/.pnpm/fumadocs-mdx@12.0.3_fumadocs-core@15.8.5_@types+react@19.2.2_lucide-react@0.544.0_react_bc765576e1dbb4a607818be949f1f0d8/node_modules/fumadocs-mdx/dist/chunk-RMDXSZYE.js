import {
  buildMDX
} from "./chunk-QAUWMR5D.js";
import {
  getGitTimestamp,
  validate
} from "./chunk-IQAEAI4P.js";
import {
  fumaMatter
} from "./chunk-VWJKRQZR.js";

// src/loaders/mdx/index.ts
import { z } from "zod";
import fs from "fs/promises";
import path from "path";
import { createHash } from "crypto";
var querySchema = z.object({
  only: z.literal(["frontmatter", "all"]).default("all"),
  collection: z.string().optional(),
  hash: z.string().describe(
    "the hash of config, used for revalidation on Turbopack/Webpack."
  ).optional()
}).loose();
var cacheEntry = z.object({
  code: z.string(),
  map: z.any().optional(),
  hash: z.string().optional()
});
function createMdxLoader(configLoader) {
  return async ({
    source: value,
    development: isDevelopment,
    query,
    compiler,
    filePath
  }) => {
    const matter = fumaMatter(value);
    const parsed = querySchema.parse(query);
    const loaded = await configLoader.getConfig(parsed.hash);
    const cacheDir = isDevelopment ? void 0 : loaded.global.experimentalBuildCache;
    const cacheKey = `${parsed.hash}_${parsed.collection ?? "global"}_${generateCacheHash(filePath)}`;
    if (cacheDir) {
      const cached = await fs.readFile(path.join(cacheDir, cacheKey)).then((content) => cacheEntry.parse(JSON.parse(content.toString()))).catch(() => null);
      if (cached && cached.hash === generateCacheHash(value)) return cached;
    }
    const collection = parsed.collection ? loaded.collections.get(parsed.collection) : void 0;
    let docCollection;
    switch (collection?.type) {
      case "doc":
        docCollection = collection;
        break;
      case "docs":
        docCollection = collection.docs;
        break;
    }
    if (docCollection?.schema) {
      matter.data = await validate(
        docCollection.schema,
        matter.data,
        {
          source: value,
          path: filePath
        },
        `invalid frontmatter in ${filePath}`
      );
    }
    if (parsed.only === "frontmatter") {
      return {
        code: `export const frontmatter = ${JSON.stringify(matter.data)}`,
        map: null
      };
    }
    const data = {};
    if (loaded.global.lastModifiedTime === "git") {
      data.lastModified = (await getGitTimestamp(filePath))?.getTime();
    }
    const lineOffset = isDevelopment ? countLines(matter.matter) : 0;
    const compiled = await buildMDX(
      `${parsed.hash ?? ""}:${parsed.collection ?? "global"}`,
      "\n".repeat(lineOffset) + matter.content,
      {
        development: isDevelopment,
        ...docCollection?.mdxOptions ?? await loaded.getDefaultMDXOptions(),
        postprocess: docCollection?.postprocess,
        data,
        filePath,
        frontmatter: matter.data,
        _compiler: compiler
      }
    );
    const out = {
      code: String(compiled.value),
      map: compiled.map
    };
    if (cacheDir) {
      await fs.mkdir(cacheDir, { recursive: true });
      await fs.writeFile(
        path.join(cacheDir, cacheKey),
        JSON.stringify({
          ...out,
          hash: generateCacheHash(value)
        })
      );
    }
    return out;
  };
}
function generateCacheHash(input) {
  return createHash("md5").update(input).digest("hex");
}
function countLines(s) {
  let num = 0;
  for (const c of s) {
    if (c === "\n") num++;
  }
  return num;
}

export {
  createMdxLoader
};
